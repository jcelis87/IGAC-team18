{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones generales para uso global\n",
    "import numpy as np\n",
    "import time\n",
    "from shapely.geometry import Polygon, Point\n",
    "import geopandas as gpd\n",
    "from shapely.ops import cascaded_union\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely import geometry\n",
    "import pandas as pd\n",
    "from geotiff import GeoTiff\n",
    "\n",
    "#Funciones para la aplicación de OCR\n",
    "import pytesseract\n",
    "#tessdata_dir_config = '--tessdata-dir \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tessdata\"'\n",
    "from PIL import ImageGrab\n",
    "import PIL\n",
    "from itertools import product\n",
    "\n",
    "#Funciones empleadas en la detección de texto\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from imutils.object_detection import non_max_suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS4A MINTIC 2021\n",
    "## Team 18, proyecto IGAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <font color='blue'> Parte 1. generación de funciones importantes </font> <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para subdividir la imagen original\n",
    "Nota: Problemas para la herencia de coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a Rasterio dataset and splits it into squares of dimensions squareDim * squareDim\n",
    "def splitImageIntoCells(img, filename, squareDim):\n",
    "    numberOfCellsWide = img.shape[1] // squareDim\n",
    "    numberOfCellsHigh = img.shape[0] // squareDim\n",
    "    x, y = 0, 0\n",
    "    count = 0\n",
    "    for hc in range(numberOfCellsHigh):\n",
    "        y = hc * squareDim\n",
    "        for wc in range(numberOfCellsWide):\n",
    "            x = wc * squareDim\n",
    "            geom = getTileGeom(img.transform, x, y, squareDim)\n",
    "            getCellFromGeom(img, geom, filename, count)\n",
    "            count = count + 1\n",
    "\n",
    "# Generate a bounding box from the pixel-wise coordinates using the original datasets transform property\n",
    "def getTileGeom(transform, x, y, squareDim):\n",
    "    corner1 = (x, y) * transform\n",
    "    corner2 = (x + squareDim, y + squareDim) * transform\n",
    "    return geometry.box(corner1[0], corner1[1],\n",
    "                        corner2[0], corner2[1])\n",
    "\n",
    "# Crop the dataset using the generated box and write it out as a GeoTIFF\n",
    "def getCellFromGeom(img, geom, filename, count):\n",
    "    crop, cropTransform = mask(img, [geom], crop=True)\n",
    "    writeImageAsGeoTIFF(crop,\n",
    "                        cropTransform,\n",
    "                        img.meta,\n",
    "                        img.crs,\n",
    "                        filename+\"_\"+str(count))\n",
    "\n",
    "# Write the passed in dataset as a GeoTIFF\n",
    "def writeImageAsGeoTIFF(img, transform, metadata, crs, filename):\n",
    "    metadata.update({\"driver\":\"GTiff\",\n",
    "                     \"height\":img.shape[1],\n",
    "                     \"width\":img.shape[2],\n",
    "                     \"transform\": transform,\n",
    "                     \"crs\": crs})\n",
    "    with rasterio.open(filename+\".tif\", \"w\", **metadata) as dest:\n",
    "        dest.write(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función opcional para dividir la imagen original\n",
    "Nota: Es opcional, fue la primera opción de divisón de imagenes, pero no hereda coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split the image depending of the d:= tile size\n",
    "def tile(filename, dir_in, dir_out, d):\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    img = PIL.Image.open(os.path.join(dir_in, filename))\n",
    "    w, h = img.size\n",
    "    \n",
    "    grid = list(product(range(0, h-h%d, d), range(0, w-w%d, d)))\n",
    "    for i, j in grid:\n",
    "        box = (j, i, j+d, i+d)\n",
    "        out = os.path.join(dir_out, f'{name}_{i}_{j}{ext}')\n",
    "        crop_image = img.crop(box)\n",
    "        crop_image = crop_image.paste( img,(j,i+d) )\n",
    "        crop_image.save(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función que genera un bounding box global de un poligono\n",
    "Nota: El poligono es el resultado de hacer \"CascadeUnion\" de la union de dos o mas BoundingBox que se intersectan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(poligon):\n",
    "    x_coordinates = list(poligon.exterior.coords.xy[0])\n",
    "    y_coordinates = list(poligon.exterior.coords.xy[1])\n",
    "\n",
    "    return Polygon([(min(x_coordinates),min(y_coordinates)),(max(x_coordinates),min(y_coordinates)),(max(x_coordinates), max(y_coordinates)),(min(x_coordinates), max(y_coordinates))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función que retorna todos Bounding Box que se tocan por Bounding\n",
    "Nota: Ingresan todos los BoundingsBox, luego determina cuales se tocan y los unen \"CascadeUnion\" y aplica \"Boundin_box\" (la función anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_geometries(geom_list):\n",
    "    #list all True intersecctions\n",
    "    news_geometries = []\n",
    "    while( len(geom_list)!=0 ):\n",
    "        logic_aux = [geom_list[0].intersects( geom_list[i] ) for i in range(0,len(geom_list) ) ]\n",
    "        indexs = np.sort( [i for i, e in enumerate(logic_aux) if e == True] )\n",
    "        news_geometries.append( bounding_box( cascaded_union( [geom_list[j] for j in indexs] ) ) )\n",
    "        acum = 0\n",
    "        for j in indexs:\n",
    "            delete = j+acum\n",
    "            geom_list.pop(delete)\n",
    "            acum -= 1\n",
    "    return news_geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función que genera los objetos tipo Polygon\n",
    "Nota: La red retorna las coordenadas donde detecto texto; Esta función retorna los polygonos detectados, su unión con \"union_geometrias\" y retorna una lista nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_rectangulos(rects):\n",
    "    geometrias = [ Polygon([ (rect[0],rect[1]),(rect[2],rect[1]),(rect[2],rect[3]),(rect[0],rect[3]),(rect[0],rect[1]) ]) for rect in rects]\n",
    "    resultado = union_geometries(geometrias)\n",
    "    new_rect = [( int( min(list(resultado[poligon].exterior.coords.xy[0])) ),int( min(list(resultado[poligon].exterior.coords.xy[1])) ),int( max(list(resultado[poligon].exterior.coords.xy[0])) ),int( max(list(resultado[poligon].exterior.coords.xy[1])) ) ) for poligon in range(0,len(resultado)) ]\n",
    "    return new_rect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <font color='blue'> Parte 2. Dividiendo la imagen original </font> <center>\n",
    "    \n",
    "    Nota: La imagen se divide respecto a la cantidad de pixeles deseados. Ejmplo: 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": "example.jpg: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_shim.pyx\u001b[0m in \u001b[0;36mrasterio._shim.open_dataset\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_err.pyx\u001b[0m in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: example.jpg: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-99377996ab56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'example.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msplitImageIntoCells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SPLIT_OUT/salida_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rasterio/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rasterio/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r+\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             s = get_writer_for_path(path, driver=driver)(\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: example.jpg: No such file or directory"
     ]
    }
   ],
   "source": [
    "fp = 'example.jpg'\n",
    "img = rasterio.open(fp)\n",
    "splitImageIntoCells(img, 'SPLIT_OUT/salida_data', 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <font color='blue'> Parte 3. Red entrenada con detección de objetos </font> <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función que aplica la red a la imagen\n",
    "Nota: Esta función es general y se aplica a la imagen que se desee grande o pequeña, pero genera mejores resultados a las pequeñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def east_detect(image, image2):\n",
    "    layerNames = [\n",
    "        \"feature_fusion/Conv_7/Sigmoid\",\n",
    "        \"feature_fusion/concat_3\"]\n",
    "    \n",
    "    orig = image.copy()\n",
    "    \n",
    "    if len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    # set the new width and height and then determine the ratio in change\n",
    "    # for both the width and height: Should be multiple of 32\n",
    "    (newW, newH) = (320, 320)\n",
    "    \n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "    \n",
    "    # resize the image and grab the new image dimensions\n",
    "    image = cv2.resize(image, (newW, newH))\n",
    "    \n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    net = cv2.dnn.readNet(\"frozen_east_text_detection.pb\")\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(image, 3, (W, H),\n",
    "        (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    \n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "    \n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    rects_2 = []\n",
    "    confidences = []\n",
    "    # loop over the number of rows\n",
    "    for y in range(0, numRows):\n",
    "        # extract the scores (probabilities), followed by the geometrical\n",
    "        # data used to derive potential bounding box coordinates that\n",
    "        # surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "    \n",
    "        for x in range(0, numCols):\n",
    "            # if our score does not have sufficient probability, ignore it\n",
    "            # Set minimum confidence as required\n",
    "            if scoresData[x] < 0.5:\n",
    "                continue\n",
    "            # compute the offset factor as our resulting feature maps will\n",
    "            #  x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "            # extract the rotation angle for the prediction and then\n",
    "            # compute the sin and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "            # use the geometry volume to derive the width and height of\n",
    "            # the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "            # compute both the starting and ending (x, y)-coordinates for\n",
    "            # the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "            # add the bounding box coordinates and probability score to\n",
    "            # our respective lists\n",
    "            \n",
    "            \"\"\"\n",
    "            pixels2coords = map_layer.xy(startX,startY) \n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "            \"\"\"\n",
    "            \n",
    "            star = image2.xy(startX,startY) \n",
    "            end = image2.xy(endX,endY) \n",
    "            rects.append(( int( np.round(star[0]) ),int( np.round(star[1])),\n",
    "                          np.round(int(end[0])),np.round(int(end[1])) ))\n",
    "            \n",
    "            rects_2.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "                        \n",
    "    rects = union_rectangulos(rects)\n",
    "    confidences = [1 for i in range(0, len(rects) )]\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "    \n",
    "    \n",
    "    rects_2 = union_rectangulos(rects_2)\n",
    "    confidences_2 = [1 for i in range(0, len(rects_2) )]\n",
    "    boxes_2 = non_max_suppression(np.array(rects_2), probs=confidences_2)\n",
    "    \n",
    "    # loop over the bounding boxes\n",
    "    for (startX, startY, endX, endY) in boxes_2:\n",
    "        # scale the bounding box coordinates based on the respective\n",
    "        # ratios\n",
    "        startX = int(startX * rW)\n",
    "        startY = int(startY * rH)\n",
    "        endX = int(endX * rW)\n",
    "        endY = int(endY * rH)\n",
    "        # draw the bounding box on the image\n",
    "        cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 5)\n",
    "    \n",
    "    \n",
    "    print(time.time() - start)\n",
    "    return orig, scoresData,rects,confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando la imagen original y se extraen las coordenadas offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargando las coordenadas del archivo para extraer las coordenadas\n",
    "with open('SPLIT_IN/example.jgwx') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "coords = [coord.replace('\\n','') for coord in lines]\n",
    "x_0 = float(coords[4].replace(',','.'))\n",
    "y_0 = float(coords[5].replace(',','.'))\n",
    "x_mov = float(coords[0].replace(',','.'))\n",
    "y_mov = float(coords[3].replace(',','.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando la detección de texto a cada imagen dividida "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25832033157348633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-dc1c0331524c>:8: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n",
      "  lista_toponimos = gpd.GeoDataFrame(crs=3116)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38372182846069336\n",
      "0.312408447265625\n",
      "0.272350549697876\n",
      "0.39411306381225586\n",
      "0.3220391273498535\n",
      "0.25575876235961914\n",
      "0.4227919578552246\n",
      "0.3855469226837158\n",
      "0.3792283535003662\n",
      "0.39560580253601074\n",
      "0.31768107414245605\n",
      "0.3766915798187256\n",
      "0.40477442741394043\n",
      "0.3901636600494385\n",
      "0.3406834602355957\n",
      "0.38347339630126953\n",
      "0.295574426651001\n",
      "0.27260351181030273\n",
      "0.38254380226135254\n",
      "0.3708186149597168\n",
      "0.30400896072387695\n",
      "0.28203582763671875\n",
      "0.25257110595703125\n",
      "0.3394043445587158\n",
      "0.32978057861328125\n",
      "0.3572874069213867\n",
      "0.33396387100219727\n",
      "0.3371715545654297\n",
      "0.282656192779541\n",
      "0.2593495845794678\n",
      "0.2741231918334961\n",
      "0.2998504638671875\n",
      "0.2956697940826416\n",
      "0.28529977798461914\n",
      "0.2960085868835449\n",
      "0.32949376106262207\n",
      "0.2986893653869629\n",
      "0.328873872756958\n",
      "0.3088681697845459\n",
      "0.3498713970184326\n",
      "0.31705665588378906\n"
     ]
    }
   ],
   "source": [
    "image_to_proces = os.listdir(path='SPLIT_OUT')\n",
    "for path in image_to_proces:\n",
    "    image2 = rasterio.open('SPLIT_OUT/'+path )\n",
    "    image = cv2.imread('SPLIT_OUT/'+path )\n",
    "    out_image,scores,rects,confidences = east_detect(image, image2)\n",
    "    cv2.imwrite('PPROCES_IMAGE_OUT/'+path , out_image)\n",
    "    \n",
    "    lista_toponimos = gpd.GeoDataFrame(crs=3116)\n",
    "    geometrias = []\n",
    "    for coords_bounding in rects:\n",
    "        x = x_0 + ( float(coords_bounding[0])*x_mov)\n",
    "        y = y_0 + ( float(coords_bounding[1])*y_mov)\n",
    "        geometrias.append( Point(x,y) )\n",
    "    \n",
    "    path_geometrias = 'GEOMETRIES_OUT/'+path.split('.')[0]+'.geojson'\n",
    "    lista_toponimos['geometry'] = geometrias\n",
    "    lista_toponimos['ID'] = [i for i in range(0, len(geometrias))]\n",
    "    try:\n",
    "        lista_toponimos.to_file(path_geometrias,driver='GeoJSON')\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <font color='red'> ANEXOS 1. Codigos de chapaleo y OCR </font> <center>\n",
    "   Nota: En esta sección se ejecutan pruebas para detección de texto y aplicación de OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading packages \n",
    "import numpy as np\n",
    "import cv2\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Creating argument dictionary for the default arguments needed in the code. \n",
    "args = {\"image\":\"example_2.jpg\", \"east\":\"east_text_detection.pb\", \"min_confidence\":0.2, \"width\":320, \"height\":320}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['image']=\"example_2.jpg\"\n",
    "image = cv2.imread(args['image'])\n",
    "\n",
    "#Saving a original image and shape\n",
    "orig = image.copy()\n",
    "(origH, origW) = image.shape[:2]\n",
    "\n",
    "# set the new height and width to default 320 by using args #dictionary.  \n",
    "(newW, newH) = (args[\"width\"], args[\"height\"])\n",
    "\n",
    "#Calculate the ratio between original and new image for both height and weight. \n",
    "#This ratio will be used to translate bounding box location on the original image. \n",
    "rW = origW / float(newW)\n",
    "rH = origH / float(newH)\n",
    "\n",
    "# resize the original image to new dimensions\n",
    "image = cv2.resize(image, (newW, newH))\n",
    "(H, W) = image.shape[:2]\n",
    "\n",
    "# construct a blob from the image to forward pass it to EAST model\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "    (123.68, 116.78, 103.94), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained EAST model for text detection \n",
    "net = cv2.dnn.readNet(\"frozen_east_text_detection.pb\")\n",
    "\n",
    "# The following two layer need to pulled from EAST model for achieving this. \n",
    "layerNames = [\n",
    "    \"feature_fusion/Conv_7/Sigmoid\",\n",
    "    \"feature_fusion/concat_3\"]\n",
    "  \n",
    "#Forward pass the blob from the image to get the desired output layers\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward(layerNames)\n",
    "\n",
    "# Returns a bounding box and probability score if it is more than minimum confidence\n",
    "def predictions(prob_score, geo):\n",
    "    (numR, numC) = prob_score.shape[2:4]\n",
    "    boxes = []\n",
    "    confidence_val = []\n",
    "\n",
    "    # loop over rows\n",
    "    for y in range(0, numR):\n",
    "        scoresData = prob_score[0, 0, y]\n",
    "        x0 = geo[0, 0, y]\n",
    "        x1 = geo[0, 1, y]\n",
    "        x2 = geo[0, 2, y]\n",
    "        x3 = geo[0, 3, y]\n",
    "        anglesData = geo[0, 4, y]\n",
    "\n",
    "        # loop over the number of columns\n",
    "        for i in range(0, numC):\n",
    "            if scoresData[i] < args[\"min_confidence\"]:\n",
    "                continue\n",
    "\n",
    "            (offX, offY) = (i * 4.0, y * 4.0)\n",
    "\n",
    "            # extracting the rotation angle for the prediction and computing the sine and cosine\n",
    "            angle = anglesData[i]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # using the geo volume to get the dimensions of the bounding box\n",
    "            h = x0[i] + x2[i]\n",
    "            w = x1[i] + x3[i]\n",
    "\n",
    "            # compute start and end for the text pred bbox\n",
    "            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))\n",
    "            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "            boxes.append((startX, startY, endX, endY))\n",
    "            confidence_val.append(scoresData[i])\n",
    "\n",
    "    boxes = union_rectangulos(boxes)\n",
    "    confidence_val = [1 for i in range(0, len(boxes) )]\n",
    "    return (boxes, confidence_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find predictions and  apply non-maxima suppression\n",
    "(boxes, confidence_val) = predictions(scores, geometry)\n",
    "boxes = non_max_suppression(np.array(boxes), probs=confidence_val)\n",
    "tessdata_dir_config = '--tessdata-dir \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tessdata\"'\n",
    "\n",
    "##Text Detection and Recognition \n",
    "\n",
    "# initialize the list of results\n",
    "results = []\n",
    "\n",
    "# loop over the bounding boxes to find the coordinate of bounding boxes\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "    # scale the coordinates based on the respective ratios in order to reflect bounding box on the original image\n",
    "    startX = int(startX * rW)\n",
    "    startY = int(startY * rH)\n",
    "    endX = int(endX * rW)\n",
    "    endY = int(endY * rH)\n",
    "\n",
    "    #extract the region of interest\n",
    "    r = orig[startY:endY, startX:endX]\n",
    "\n",
    "    #configuration setting to convert image to string.  \n",
    "    configuration = (\"-l eng --oem 1 --psm 8\")\n",
    "    ##This will recognize the text from the image of bounding box\n",
    "    text = pytesseract.image_to_string(r, config=tessdata_dir_config, lang='spa_old')\n",
    "\n",
    "    # append bbox coordinate and associated text to the list of results \n",
    "    results.append(((startX, startY, endX, endY), text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the image with bounding box and recognized text\n",
    "orig_image = orig.copy()\n",
    "\n",
    "# Moving over the results and display on the image\n",
    "for ((start_X, start_Y, end_X, end_Y), text) in results:\n",
    "    # display the text detected by Tesseract\n",
    "    print(\"{}\\n\".format(text))\n",
    "\n",
    "    # Displaying text\n",
    "    text = \"\".join([x if ord(x) < 128 else \"\" for x in text]).strip()\n",
    "    cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),\n",
    "        (0, 0, 255), 2)\n",
    "    cv2.putText(orig_image, text, (start_X, start_Y - 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0, 255), 2)\n",
    "\n",
    "plt.imshow(orig_image)\n",
    "plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <font color='red'> ANEXOS 2. Codigos de chapaleo y testeo general</font> <center>\n",
    "    \n",
    "    Nota: En esta sección se ejecutan pruebas, por tanto puede que algunas celdas no funcionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extent(dataset):\n",
    "    cols = dataset.RasterXSize\n",
    "    rows = dataset.RasterYSize\n",
    "    transform = dataset.GetGeoTransform()\n",
    "    minx = transform[0]\n",
    "    maxx = transform[0] + cols * transform[1] + rows * transform[2]\n",
    "\n",
    "    miny = transform[3] + cols * transform[4] + rows * transform[5]\n",
    "    maxy = transform[3]\n",
    "\n",
    "    return {\n",
    "            \"minX\": str(minx), \"maxX\": str(maxx),\n",
    "            \"minY\": str(miny), \"maxY\": str(maxy),\n",
    "            \"cols\": str(cols), \"rows\": str(rows)\n",
    "            }\n",
    "\n",
    "def create_tiles(minx, miny, maxx, maxy, n):\n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "\n",
    "    matrix = []\n",
    "\n",
    "    for j in range(n, 0, -1):\n",
    "        for i in range(0, n):\n",
    "\n",
    "            ulx = minx + (width/n) * i # 10/5 * 1\n",
    "            uly = miny + (height/n) * j # 10/5 * 1\n",
    "\n",
    "            lrx = minx + (width/n) * (i + 1)\n",
    "            lry = miny + (height/n) * (j - 1)\n",
    "            matrix.append([[ulx, uly], [lrx, lry]])\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def split(file_name, n):\n",
    "    raw_file_name = os.path.splitext(os.path.basename(file_name))[0].replace(\"_downsample\", \"\")\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    dataset = gdal.Open(file_name)\n",
    "    band = dataset.GetRasterBand(1)\n",
    "    transform = dataset.GetGeoTransform()\n",
    "\n",
    "    extent = get_extent(dataset)\n",
    "\n",
    "    cols = int(extent[\"cols\"])\n",
    "    rows = int(extent[\"rows\"])\n",
    "\n",
    "    ##print \"Columns: \", cols\n",
    "    ##print \"Rows: \", rows\n",
    "\n",
    "    minx = float(extent[\"minX\"])\n",
    "    maxx = float(extent[\"maxX\"])\n",
    "    miny = float(extent[\"minY\"])\n",
    "    maxy = float(extent[\"maxY\"])\n",
    "\n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "\n",
    "    output_path = os.path.join(\"data\", raw_file_name)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    ###print \"GCD\", gcd(round(width, 0), round(height, 0))\n",
    "    ##print \"Width\", width\n",
    "    ##print \"height\", height\n",
    "\n",
    "\n",
    "    tiles = create_tiles(minx, miny, maxx, maxy, n)\n",
    "    transform = dataset.GetGeoTransform()\n",
    "    xOrigin = transform[0]\n",
    "    yOrigin = transform[3]\n",
    "    pixelWidth = transform[1]\n",
    "    pixelHeight = -transform[5]\n",
    "\n",
    "    ##print xOrigin, yOrigin\n",
    "\n",
    "    tile_num = 0\n",
    "    for tile in tiles:\n",
    "\n",
    "        minx = tile[0][0]\n",
    "        maxx = tile[1][0]\n",
    "        miny = tile[1][1]\n",
    "        maxy = tile[0][1]\n",
    "\n",
    "        p1 = (minx, maxy)\n",
    "        p2 = (maxx, miny)\n",
    "\n",
    "        i1 = int((p1[0] - xOrigin) / pixelWidth)\n",
    "        j1 = int((yOrigin - p1[1])  / pixelHeight)\n",
    "        i2 = int((p2[0] - xOrigin) / pixelWidth)\n",
    "        j2 = int((yOrigin - p2[1]) / pixelHeight)\n",
    "\n",
    "        #print i1, j1\n",
    "        #print i2, j2\n",
    "\n",
    "        new_cols = i2-i1\n",
    "        new_rows = j2-j1\n",
    "\n",
    "        data = band.ReadAsArray(i1, j1, new_cols, new_rows)\n",
    "\n",
    "        #print data\n",
    "\n",
    "        new_x = xOrigin + i1*pixelWidth\n",
    "        new_y = yOrigin - j1*pixelHeight\n",
    "\n",
    "        ##print new_x, new_y\n",
    "\n",
    "        new_transform = (new_x, transform[1], transform[2], new_y, transform[4], transform[5])\n",
    "\n",
    "        output_file_base = raw_file_name + \"_\" + str(tile_num) + \".tif\"\n",
    "        output_file = os.path.join(\"data\", raw_file_name, output_file_base)\n",
    "\n",
    "        dst_ds = driver.Create(output_file,\n",
    "                               new_cols,\n",
    "                               new_rows,\n",
    "                               1,\n",
    "                               gdal.GDT_Float32)\n",
    "\n",
    "        #writting output raster\n",
    "        dst_ds.GetRasterBand(1).WriteArray( data )\n",
    "\n",
    "        tif_metadata = {\n",
    "            \"minX\": str(minx), \"maxX\": str(maxx),\n",
    "            \"minY\": str(miny), \"maxY\": str(maxy)\n",
    "        }\n",
    "        dst_ds.SetMetadata(tif_metadata)\n",
    "\n",
    "        #setting extension of output raster\n",
    "        # top left x, w-e pixel resolution, rotation, top left y, rotation, n-s pixel resolution\n",
    "        dst_ds.SetGeoTransform(new_transform)\n",
    "\n",
    "        wkt = dataset.GetProjection()\n",
    "\n",
    "        # setting spatial reference of output raster\n",
    "        srs = osr.SpatialReference()\n",
    "        srs.ImportFromWkt(wkt)\n",
    "        dst_ds.SetProjection( srs.ExportToWkt() )\n",
    "\n",
    "        #Close output raster dataset\n",
    "        dst_ds = None\n",
    "\n",
    "        tile_num += 1\n",
    "\n",
    "    dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split('SPLIT_IN/example.jpg', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open(os.path.join('SPLIT_IN', 'example.jpg'))\n",
    "img.save('SPLIT_OUT/EXAMPLE.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
